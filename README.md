# ğŸ¤ Voice Activity Detection (VAD) App

This Streamlit application performs **Voice Activity Detection** and **Speech-to-Text transcription** using:

- ğŸ§  OpenAI's Whisper
- ğŸ§  Facebook's Wav2Vec2
- ğŸ“ˆ Energy-based VAD with visualizations

Supports both **WAV file uploads** and **real-time microphone input**.

---

## ğŸš€ Features

- ğŸ”Š Upload or record audio
- ğŸ¯ Detect voice activity using frequency-energy analysis
- ğŸ§¾ Transcribe audio with Whisper and Wav2Vec2
- ğŸ“Š Interactive waveform plots with voice segment overlays
- âš™ï¸ Adjustable VAD parameters

---

## ğŸ“¦ Installation

Follow these steps to set up the Voice Activity Detection (VAD) App on your local machine.

### 1. Clone the repository

```bash
git clone https://github.com/AyushPoojariUCD/Voice-Activity-Detection.git
```

### 2. Navigate to the project directory
```
cd Voice-Activity-Detection
```

### 3. Create a virtual environment
```
python -m venv venv
```

### 4. Install dependencies
```
pip install -r requirements.txt
```
#### or
```
pip install numpy scipy scikit-learn librosa streamlit openai torch torchaudio
```

### 5. Run the application
```
streamlit run app.py
```


### ğŸ“‚ Project Structure

Voice-Activity-Detection/
â”œâ”€â”€ README.md                      # Project overview and setup guide
â”œâ”€â”€ app.py                         # Streamlit app for Voice Activity Detection
â”œâ”€â”€ requirements.txt               # List of dependencies
â”œâ”€â”€ utils/                         # Utility functions
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ frequency_energy_utils.py  # Functions for processing audio files
â”œâ”€â”€ models/                        # Directory for models
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ cnn_model.py               # VAD ML-based model will be added later
|   |__ transformer_model          # VAD Transformer based model will be added later
|
â”œâ”€â”€ data/                          # Directory for storing datasets
â”‚   â””â”€â”€ audio_samples/             # Example audio samples for testing
â”œâ”€â”€ logs/                          # Logs of predictions, performance metrics and monitoring application will be added later
â””â”€â”€ .env                           # Environment variables will be added later


### ğŸ“Œ Project Code that will be updated

### 1. **Integration with CNN Models**:
We will integrate **Convolutional Neural Networks (CNNs)** for more accurate voice activity detection and also transformer. 

### 2. **WebRTC Integration**:
We plan to add **WebRTC** (Web Real-Time Communication) capabilities to capture audio streams directly from web browsers in real-time. This integration will enable seamless VAD for live audio without the need for pre-recorded files.

### 3. **More VAD will be integrated**:
We plan to add more VAD for integration and compare them.

### 4. **Model Comparison**:
We'll compare the performance of **energy-based VAD**, **CNN models**, **WebRTC**, and **Pico Voice** in terms of **accuracy**, **speed**, and **robustness**. This comparative study will help identify the most effective VAD approach for different applications and use cases.
